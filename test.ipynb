{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anchors = [[5,5,5],[10,10,10],[15,15,15],[20,20,20],[30,30,30],[5,5,2.5],[10,10,5],[15,15,7.5],[20,20,10],[30,30,15]]\n",
    "# anchors = [[5,5,5],[10,10,10],[15,15,15],[20,20,20],[30,30,30]]\n",
    "anchors = [[6,6,6],[12,12,12],[24,24,24],[9,9,6],[18,18,12],[36,36,24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_rpn_windows(f_shape):\n",
    "    \"\"\"\n",
    "    Generating anchor boxes at each voxel on the feature map,\n",
    "    the center of the anchor box on each voxel corresponds to center\n",
    "    on the original input image.\n",
    "\n",
    "    return\n",
    "    windows: list of anchor boxes, [z, y, x, d, h, w]\n",
    "    \"\"\"\n",
    "    stride = 4\n",
    "    anchors = np.asarray(anchors)\n",
    "    offset = (float(stride) - 1) / 2\n",
    "    _, _, D, H, W = f_shape\n",
    "    oz = np.arange(offset, offset + stride * (D - 1) + 1, stride)\n",
    "    oh = np.arange(offset, offset + stride * (H - 1) + 1, stride)\n",
    "    ow = np.arange(offset, offset + stride * (W - 1) + 1, stride)\n",
    "\n",
    "    windows = []\n",
    "    for z, y, x, a in itertools.product(oz, oh , ow , anchors):\n",
    "        windows.append([z, y, x, a[0], a[1], a[2]])\n",
    "    windows = np.array(windows)\n",
    "\n",
    "    return windows\n",
    "\n",
    "def find_nearest(x,y,z):\n",
    "    stride = 4\n",
    "    start = (stride-1) / 2\n",
    "    z_stride = 4\n",
    "    z_start = (z_stride-1) / 2\n",
    "    xl = ((x - start) // stride) *stride + start\n",
    "    xr = xl+stride\n",
    "    xn = xl if x-xl < xr-x else xr\n",
    "\n",
    "    yl = ((y - start) // stride) *stride + start\n",
    "    yr = yl+stride\n",
    "    yn = yl if y-yl < yr-y else yr\n",
    "\n",
    "    zl = ((z - z_start) // z_stride) *z_stride + z_start\n",
    "    zr = zl+z_stride\n",
    "    zn = zl if z-zl < zr-z else zr\n",
    "\n",
    "    return xn, yn, zn\n",
    "\n",
    "def IoU(cord1, shape, cord2, shape2):\n",
    "    x1, y1, z1 = cord1\n",
    "    w, h, d = shape      # nodule bbox shape\n",
    "    x2, y2, z2 = cord2\n",
    "    aw, ah, ad = shape2  # anchor shape\n",
    "\n",
    "    x_overlap = min(x1+w/2, x2+aw/2) - max(x1-w/2, x2-aw/2) if (max(x1+w/2, x2+aw/2)-min(x1-w/2, x2-aw/2)) < w+aw else 0\n",
    "    y_overlap = min(y1+h/2, y2+ah/2) - max(y1-h/2, y2-ah/2) if (max(y1+h/2, y2+ah/2)-min(y1-h/2, y2-ah/2)) < h+ah else 0\n",
    "    z_overlap = min(z1+d/2, z2+ad/2) - max(z1-d/2, z2-ad/2) if (max(z1+d/2, z2+ad/2)-min(z1-d/2, z2-ad/2)) < d+ad else 0\n",
    "    v = x_overlap * y_overlap*z_overlap\n",
    "    return v / (w*h*d+aw*ah*ad-v)\n",
    "\n",
    "def distance(cord1, cord2):\n",
    "    x1, y1, z1 = cord1\n",
    "    x2, y2, z2 = cord2\n",
    "    return ((x1-x2)**2 + (y1-y2)**2 + (z1-z2)**2)\n",
    "\n",
    "def DIoU(cord1, shape, cord2, shape2):\n",
    "    x1, y1, z1 = cord1\n",
    "    w, h, d = shape      # nodule bbox shape\n",
    "    x2, y2, z2 = cord2\n",
    "    aw, ah, ad = shape2  # anchor shape\n",
    "\n",
    "    c1 = [max(x1+w/2, x2+aw/2), max(y1+h/2, y2+ah/2), max(z1+d/2, z2+ad/2)]\n",
    "    c2 = [min(x1-w/2, x2-aw/2), min(y1-h/2, y2-ah/2), min(z1-d/2, z2-ad/2)]\n",
    "\n",
    "    return IoU(cord1, shape, cord2, shape2) - distance(cord1, cord2)/distance(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329, 1491, 76, 1387, 615, 36] \n",
      " [0, 3, 46, 1761] \n",
      " [1, 1809]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "nodule_distribution = [0,0,0,0]\n",
    "anchor_distribution = [0 for i in range(len(anchors))]\n",
    "\n",
    "train_txt = r'F:\\master\\code\\Lung_Nodule\\FL_lung_nodule_datasplit_ME_LDCT\\client0_train.txt'\n",
    "with open(train_txt, 'r') as f:\n",
    "    train_files = f.readlines()\n",
    "anchor_count = [0,0]\n",
    "bad_nodule = []\n",
    "for train_file in train_files[1:]:\n",
    "    p1, p2 = train_file.replace('\\n','').split(',')\n",
    "\n",
    "    dicom_nodule_path = os.path.join(p1, 'mask', f'{p2}_nodule_count.json') # CHEST1001_nodule_count\n",
    "    with open(dicom_nodule_path, 'r') as f:\n",
    "        dicom_nodule = json.load(f)\n",
    "    nodules = dicom_nodule['bboxes']\n",
    "    good_nodule = 0\n",
    "    for nodule in nodules:\n",
    "        cx = (nodule[0][0]+nodule[1][0])/2\n",
    "        cy = (nodule[0][1]+nodule[1][1])/2\n",
    "        cz = (nodule[0][2]+nodule[1][2])/2\n",
    "        w = (nodule[1][0]-nodule[0][0])+4\n",
    "        h = (nodule[1][1]-nodule[0][1])+4\n",
    "        d = (nodule[1][2]-nodule[0][2])+4\n",
    "\n",
    "        size = (4/3)*3.1415*(h*w*d / 6)\n",
    "        if size <= 52:\n",
    "            size_idx = 0\n",
    "        elif size <= 113:\n",
    "            size_idx = 1\n",
    "        elif size <= 268:\n",
    "            size_idx = 2\n",
    "        else:\n",
    "            size_idx = 3\n",
    "\n",
    "        nodule_distribution[size_idx] += 1\n",
    "\n",
    "        nearest_point = find_nearest(cx, cy, cz)\n",
    "\n",
    "        for i, anchor in enumerate(anchors):\n",
    "            if IoU([cx,cy,cz], [w,h,d], nearest_point, anchor) >= 0.3:\n",
    "                anchor_distribution[i] += 1\n",
    "                good_nodule = 1\n",
    "\n",
    "        anchor_count[good_nodule] += 1\n",
    "        if not good_nodule:\n",
    "            bad_nodule.append([size_idx, w,h,d])\n",
    "print(anchor_distribution, '\\n', nodule_distribution, '\\n', anchor_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10131108462455304"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '362\t276\t262.5\t11\t7\t6'\n",
    "b = '359.5\t278\t258.5\t6\t5\t2'\n",
    "a = a.split('\\t')\n",
    "a_cord = [float(a_) for a_ in a[:3]]\n",
    "a_shape = [float(a_) for a_ in a[3:]]\n",
    "b = b.split('\\t')\n",
    "b_cord = [float(b_) for b_ in b[:3]]\n",
    "b_shape = [float(b_) for b_ in a[3:]]\n",
    "IoU(a_cord, a_shape, b_cord, b_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = r'F:\\master\\code\\LSSANet-main\\MsaNet_R_results\\ME_LDCT\\AdamW0.0003_Bs6x4_OHEM10_bb0\\res\\72\\FROC\\submission_rpn.csv'\n",
    "gt_path  = r'F:\\master\\code\\Lung_Nodule\\FL_lung_nodule_datasplit_ME_LDCT\\client0_test_annotation.csv'\n",
    "\n",
    "import csv\n",
    "sub_by_file = {}\n",
    "with open(sub_path, newline='') as fs:\n",
    "    subs = csv.reader(fs,)\n",
    "    for sub in subs:\n",
    "        if sub[0] in sub_by_file.keys():\n",
    "            sub_by_file[sub[0]].append([float(xyzhwd) for xyzhwd in sub[1:8]])\n",
    "        elif sub[0] != 'series_id':\n",
    "            sub_by_file[sub[0]] = [[float(xyzhwd) for xyzhwd in sub[1:8]]]\n",
    "\n",
    "gt_by_file  = {}\n",
    "with open(gt_path, newline='') as fg:\n",
    "    gts = csv.reader(fg)\n",
    "    for gt in gts:\n",
    "        if gt[0] in gt_by_file.keys():\n",
    "            gt_by_file[gt[0]].append([float(xyzhwd) for xyzhwd in gt[1:8]])\n",
    "        elif gt[0] != 'series_id':\n",
    "            gt_by_file[gt[0]] = [[float(xyzhwd) for xyzhwd in gt[1:8]]]\n",
    "\n",
    "files = list(gt_by_file.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = []\n",
    "FN = []\n",
    "gt_IoU = []\n",
    "gt_DIoU = []\n",
    "for file in files:\n",
    "    gts = gt_by_file[file]\n",
    "    subs = sub_by_file[file]\n",
    "    for gt in gts:\n",
    "        is_cand = 0\n",
    "        re_detected = 0\n",
    "        max_iou = 0.0\n",
    "        max_diou = 0.0\n",
    "        gt_cord, gt_shape = gt[:3], gt[3:6]\n",
    "        for sub in subs:\n",
    "            iou = IoU(gt_cord, gt_shape, sub[:3], sub[3:6])\n",
    "            if iou >= 0.1:\n",
    "                if is_cand:\n",
    "                    re_detected += 1\n",
    "                is_cand = 1\n",
    "            max_iou = max(max_iou, iou)\n",
    "            max_diou = max(max_diou, DIoU(gt_cord, gt_shape, sub[:3], sub[3:6]))\n",
    "        gt_IoU.append([max_iou, max_diou])\n",
    "        gt_DIoU.append(max_diou)\n",
    "        if is_cand:\n",
    "            TP.append(max_iou)\n",
    "        else:\n",
    "            FN.append(max_iou)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "from single_config import config\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def crop_with_lobe(z:str, yx:str):\n",
    "    zlobe = z.replace('\\n','').split(',')\n",
    "    Ds, De = [int(z_) for z_ in zlobe]\n",
    "    yxlobe = yx.replace('\\n','').split(',')\n",
    "    Hs, He, Ws, We = [int(yx_) for yx_ in yxlobe]\n",
    "    \n",
    "    # align to 16\n",
    "    align = 16\n",
    "    Ds = (Ds//align)*align\n",
    "    De = ((De+align-1)//align)*align\n",
    "    Hs = (Hs//align)*align\n",
    "    He = ((He+align-1)//align)*align\n",
    "    Ws = (Ws//align)*align\n",
    "    We = ((We+align-1)//align)*align\n",
    "\n",
    "    return (Ds, De, Hs, He, Ws, We)\n",
    "\n",
    "def load_img(filename):\n",
    "    path, dir = filename.split(',')\n",
    "    img = np.load('%s\\\\npy\\\\%s.npy' % (path, dir))\n",
    "    # img = img[np.newaxis,...] # (y, x, z) -> (1, y, x, z)\n",
    "    ## load lobe info\n",
    "    with open('%s\\\\npy\\\\lobe_info.txt' %(path)) as f:\n",
    "        lobe_info = f.readlines()[-2:]\n",
    "    with open('%s\\\\mask\\\\%s_nodule_count.json' % (path, dir)) as f:\n",
    "        nodule_count = json.load(f)\n",
    "    bboxes = nodule_count['bboxes']\n",
    "    Ds, De, Hs, He, Ws, We = crop_with_lobe(*lobe_info)\n",
    "    # crop the lobe\n",
    "    img = img[np.newaxis, Hs:He, Ws:We, Ds:De]\n",
    "\n",
    "    img = np.clip(img, -1000, 400)\n",
    "    img = img.astype(np.float32)\n",
    "    img = img.transpose(0, 3, 1, 2) # (1, y, x, z) -> (1, z, y, x)\n",
    "    images = img + 1000    # 0 ~ max\n",
    "    images = (images - 700) / 700 # -1 ~ 1\n",
    "    return images, (Ds, De, Hs, He, Ws, We), bboxes\n",
    "\n",
    "class Crop(object):\n",
    "    def __init__(self, config):\n",
    "        self.crop_size = config['crop_size']\n",
    "        self.bound_size = config['bound_size']\n",
    "        self.stride = config['stride']\n",
    "        self.pad_value = config['pad_value']\n",
    "\n",
    "    def __call__(self, imgs, target, bboxes, lobe=None, isScale=False, isRand=False):\n",
    "        '''\n",
    "        img: 3D image loading from npy, (1, d, h, w)\n",
    "        target: one nodule\n",
    "        bboxes: all nodules in series\n",
    "        '''\n",
    "        if isScale:\n",
    "            radiusLim = [8.,120.]\n",
    "            scaleLim = [0.75,1.25]\n",
    "            scaleRange = [np.min([np.max([(radiusLim[0]/target[3]),scaleLim[0]]),1])\n",
    "                         ,np.max([np.min([(radiusLim[1]/target[3]),scaleLim[1]]),1])]\n",
    "            scale = np.random.rand()*(scaleRange[1]-scaleRange[0])+scaleRange[0]\n",
    "            crop_size = (np.array(self.crop_size).astype('float')/scale).astype('int')\n",
    "        else:\n",
    "            crop_size = self.crop_size\n",
    "        bound_size = self.bound_size\n",
    "        target = np.copy(target)\n",
    "        bboxes = np.copy(bboxes)\n",
    "        start = []\n",
    "        for i in range(3):\n",
    "            # start.append(int(target[i] - crop_size[i] / 2))\n",
    "            if not isRand:\n",
    "                # crop the sample base on target\n",
    "                r = target[i+3]/2\n",
    "                s = np.floor(target[i] - r) + 1 - bound_size\n",
    "                e = np.ceil(target[i] + r) + 1 + bound_size - crop_size[i]\n",
    "            else:\n",
    "                # crop the sample randomly\n",
    "                s = np.max([imgs.shape[i+1]-crop_size[i]/2, imgs.shape[i+1]/2+bound_size])\n",
    "                e = np.min([crop_size[i]/2, imgs.shape[i+1]/2-bound_size])\n",
    "                target = np.array([np.nan, np.nan, np.nan, np.nan])\n",
    "            if s > e:\n",
    "                i_start = np.random.randint(e, s)\n",
    "                i_start = max(min(i_start, imgs.shape[i+1]-crop_size[i]),0)\n",
    "                start.append(i_start)#!\n",
    "            else:\n",
    "                start.append(int(target[i])-crop_size[i]/2+np.random.randint(-bound_size/2,bound_size/2))\n",
    "\n",
    "        coord=[]\n",
    "        pad = []\n",
    "        pad.append([0,0])\n",
    "\n",
    "        for i in range(3):\n",
    "            leftpad = max(0,-start[i]) # how many pixel need to pad on the left side\n",
    "            rightpad = max(0,start[i]+crop_size[i]-imgs.shape[i+1]) # how many pixel need to pad on the right side\n",
    "            pad.append([leftpad,rightpad])\n",
    "            \n",
    "        crop = imgs[:,\n",
    "            int(max(start[0],0)):int(min(start[0] + int(crop_size[0]),imgs.shape[1])),\n",
    "            int(max(start[1],0)):int(min(start[1] + int(crop_size[1]),imgs.shape[2])),\n",
    "            int(max(start[2],0)):int(min(start[2] + int(crop_size[2]),imgs.shape[3]))]\n",
    "\n",
    "        crop = np.pad(crop, pad, 'constant', constant_values=0.67142)\n",
    "        for i in range(3):\n",
    "            target[i] = target[i] - start[i]\n",
    "        for i in range(len(bboxes)):\n",
    "            for j in range(3):\n",
    "                bboxes[i][j] = bboxes[i][j] - start[j]\n",
    "\n",
    "        if isScale:\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                crop = zoom(crop, [1, scale, scale, scale], order=1)\n",
    "            newpad = self.crop_size[0] - crop.shape[1:][0]\n",
    "            if newpad < 0:\n",
    "                crop = crop[:, :-newpad, :-newpad, :-newpad]\n",
    "            elif newpad > 0:\n",
    "                pad2 = [[0, 0], [0, newpad], [0, newpad], [0, newpad]]\n",
    "                crop = np.pad(crop, pad2, 'constant', constant_values=0.67142)\n",
    "            for i in range(6):\n",
    "                target[i] = target[i] * scale\n",
    "            for i in range(len(bboxes)):\n",
    "                for j in range(6):\n",
    "                    bboxes[i][j] = bboxes[i][j] * scale\n",
    "\n",
    "        return crop, target, bboxes, coord\n",
    "\n",
    "crop = Crop(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt = r'F:\\master\\code\\Lung_Nodule\\FL_lung_nodule_datasplit_ME_LDCT\\client0_test.txt'\n",
    "with open(test_txt, 'r') as f:\n",
    "    files = f.readlines()\n",
    "imgs, lobe_info, bboxes = load_img(files[1])\n",
    "bboxes = bboxes - [lobe_info[0], lobe_info[2], lobe_info[4], 0, 0, 0]\n",
    "for bbox in bboxes:\n",
    "    sample, target, bboxes, coord = crop(imgs, bbox, bboxes, isScale=False, isRand=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from utils.util import crop_with_lobe\n",
    "test_dicom_npy = r'F:\\master\\code\\Lung_Nodule\\dataset\\LDCT_test_dataset\\CHESTCT_Test0014\\npy\\CHESTCT_Test0014.npy'\n",
    "test_dicom_info = r'F:\\master\\code\\Lung_Nodule\\dataset\\LDCT_test_dataset\\CHESTCT_Test0014\\mask\\CHESTCT_Test0014_nodule_count.json'\n",
    "test_dicom_lobe = r'F:\\master\\code\\Lung_Nodule\\dataset\\LDCT_test_dataset\\CHESTCT_Test0014\\npy\\lobe_info.txt'\n",
    "\n",
    "filename = [r'F:\\master\\code\\Lung_Nodule\\dataset\\LDCT_test_dataset\\CHESTCT_Test0014', 'CHESTCT_Test0014']\n",
    "path, dir = filename\n",
    "img = np.load(os.path.join('%s\\\\npy\\\\%s.npy' % (path, dir)))\n",
    "img = img[np.newaxis,...] # (y, x, z) -> (1, y, x, z)\n",
    "## load lobe info\n",
    "with open(os.path.join('%s\\\\npy\\\\lobe_info.txt' %(path))) as f:\n",
    "    # ['z_start,z_end\\n',\n",
    "    #  'y_start,y_end,x_start,x_end']\n",
    "    lobe_info = f.readlines()[-2:]\n",
    "    lobes = crop_with_lobe(*lobe_info)\n",
    "\n",
    "with open(test_dicom_info, 'r') as f:\n",
    "    dicom_info = json.load(f)\n",
    "    nodules = dicom_info[\"bboxes\"]\n",
    "bboxes = []\n",
    "for nodule in nodules:\n",
    "    nodule = np.array(nodule)\n",
    "    cx, cy, cz = (nodule[1,:] + nodule[0,:]+1) /2\n",
    "    w,  h,  d  = (nodule[1,:] - nodule[0,:]+1)\n",
    "    bboxes.append(np.array([0.,cx, cy, cz, w, h, d]))\n",
    "bboxes = np.array(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 288, 128, 400, 64, 448)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lobes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 330 250\n"
     ]
    }
   ],
   "source": [
    "from utils.pybox import *\n",
    "import torch\n",
    "while True:\n",
    "    overlap_nodule = False\n",
    "    rz = np.random.randint(lobes[0]+64, lobes[1]-64)\n",
    "    ry = np.random.randint(lobes[2]+64, lobes[3]-64)\n",
    "    rx = np.random.randint(lobes[4]+64, lobes[5]-64)\n",
    "    overlaps = torch_overlap(bboxes[:,-6:], np.array([rx, ry, rz, 128, 128, 128]))\n",
    "    for overlap in overlaps:\n",
    "        if overlap[0] > 0.02:\n",
    "            overlap_nodule = True\n",
    "            break\n",
    "    if overlap_nodule:\n",
    "        break\n",
    "    else:\n",
    "        count += 1\n",
    "        print(f'{rz} {ry} {rx} overlapped with nodule')\n",
    "print(rz, ry, rx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(img, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 7\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (1, y, x, z) -> (1, z, y, x)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m images \u001b[38;5;241m=\u001b[39m img \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1000\u001b[39m    \u001b[38;5;66;03m# 0 ~ max\u001b[39;00m\n\u001b[0;32m      9\u001b[0m images \u001b[38;5;241m=\u001b[39m (images \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m700\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m700\u001b[39m \u001b[38;5;66;03m# -1 ~ 1\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "Ds, De, Hs, He, Ws, We = crop_with_lobe(*lobe_info)\n",
    "# crop the lobe\n",
    "img = img[np.newaxis, Hs:He, Ws:We, Ds:De]\n",
    "\n",
    "img = np.clip(img, -1000, 400)\n",
    "img = img.astype(np.float32)\n",
    "img = img.transpose(0, 3, 1, 2) # (1, y, x, z) -> (1, z, y, x)\n",
    "images = img + 1000    # 0 ~ max\n",
    "images = (images - 700) / 700 # -1 ~ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 265 143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([], size=(0, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rz = np.random.randint(lobes[0]+64, lobes[1]-64)\n",
    "ry = np.random.randint(lobes[2]+64, lobes[3]-64)\n",
    "rx = np.random.randint(lobes[4]+64, lobes[5]-64)\n",
    "print(rz, ry, rx)\n",
    "torch_overlap(np.array([]), np.array([rx, ry, rz, 128, 128,128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(len(bboxes), min(len(bboxes),2), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. , 332.5, 171. ,  71.5,   7. ,   6. ,   5. ],\n",
       "       [  0. , 335. , 407. , 251.5,  12. ,  10. ,   9. ],\n",
       "       [  0. , 368.5, 185.5, 141. ,   5. ,   7. ,   6. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FGD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
